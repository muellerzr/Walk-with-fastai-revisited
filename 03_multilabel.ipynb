{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14702a64-48c1-4ab8-b202-e5d3784910ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb93279-3597-4dac-a63f-ac1c1bc85c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import tensor\n",
    "from torchvision.models.resnet import resnet34\n",
    "from PIL import Image\n",
    "from itertools import compress\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from fastcore.xtras import Path\n",
    "\n",
    "from fastai.data.core import show_at, Datasets\n",
    "from fastai.data.external import URLs, untar_data\n",
    "from fastai.data.transforms import (\n",
    "    ColReader,\n",
    "    IntToFloatTensor, \n",
    "    MultiCategorize, \n",
    "    Normalize,\n",
    "    OneHotEncode, \n",
    "    RandomSplitter,\n",
    ")\n",
    "\n",
    "from fastai.metrics import accuracy_multi\n",
    "\n",
    "from fastai.vision.augment import aug_transforms\n",
    "from fastai.vision.core import PILImage\n",
    "from fastai.vision.learner import vision_learner\n",
    "from fastai.learner import Learner\n",
    "from fastai.callback.schedule import Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68b5019e-86f7-4750-adb9-745d18ac1adf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "src = untar_data(URLs.PLANET_SAMPLE)\n",
    "df = pd.read_csv(src/'labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba23ad72-f155-4627-8775-04203a3c2060",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d115ffaf-9fc7-46f6-9f10-7af399acae74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_tags = df[\"tags\"].values\n",
    "all_labels = []\n",
    "for row in all_tags:\n",
    "    all_labels += row.split(\" \")\n",
    "len(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "382633fb-3b76-4547-b1b6-4441a7403ebb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "different_labels = set(all_labels)\n",
    "len(different_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e749245e-db15-4c62-9363-0cad2a59ed86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "counts = {\n",
    "    label: all_labels.count(label) \n",
    "    for label in different_labels\n",
    "}\n",
    "\n",
    "counts = {\n",
    "    key: value \n",
    "    for key, value in \n",
    "    sorted(\n",
    "        counts.items(), \n",
    "        key = lambda item: -item[1]\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10048a95-6db6-4dfb-8db4-72d1c55769b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3283dfcd-f750-4afc-9982-946a1f01e4da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de663a78-3d39-42f5-a8b4-248193ed5a62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for key, count in counts.items():\n",
    "    if count < 10:\n",
    "        df = df[df[\"tags\"].str.contains(key) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2831e62-4a79-4091-b71b-bfe77e8c7538",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c431bda-f8be-4dff-962b-d3fb38c9742b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"image_name\"].head(), src.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bf44fc9-b12d-48e5-8efd-b9dd3acf7024",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(src/'train').ls()[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ad5f7f6-a660-44b0-94f2-47f9f1775fae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PILImage.create((src/'train'/'train_2407.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d517878-7b30-4223-9351-aee5e9ac5dee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_x(row:pd.Series) -> Path:\n",
    "    return (src/'train'/row.image_name).with_suffix(\".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5748c3b8-9c13-4b73-a7a0-e09ecb9bdf5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_y(row:pd.Series) -> List[str]:\n",
    "    return row.tags.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d923e47b-695b-4111-8c3c-7fb31220cb39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "row = df.iloc[0]\n",
    "get_x(row), get_y(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fe37edd-2632-4f78-b304-a87e7c521912",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_x = ColReader(0, pref=f'{src}/train/', suff=\".jpg\")\n",
    "get_y = ColReader(1, label_delim=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7ac3d9b-55e3-409d-95ec-2fa28bf9c331",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tfms = [\n",
    "    [get_x, PILImage.create], \n",
    "    [\n",
    "        get_y,\n",
    "        MultiCategorize(vocab=different_labels), \n",
    "        OneHotEncode(len(different_labels))\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e15b8f4f-783f-4c2e-a604-c0147bc6e69a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_idxs, valid_idxs = (\n",
    "    RandomSplitter(valid_pct=0.2, seed=42)(df)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a325977-62fa-4ce4-a12c-d4cfa4decf1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_idxs, valid_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35cbf350-f37a-4447-ace7-5e931e2084c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dsets = Datasets(df, tfms=tfms, splits=[train_idxs, valid_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cabc4923-cad7-42d5-b65a-be04548f2a72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dsets.train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fbe5db-6d13-4e68-8472-ad9a953cd2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_at(dsets.train, 0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b641b198-94fe-4a32-a4ff-a4754f8ded02",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_tfms = [\n",
    "    IntToFloatTensor(), \n",
    "    *aug_transforms(\n",
    "        flip_vert=True, \n",
    "        max_lighting=0.1, \n",
    "        max_zoom=1.05, \n",
    "        max_warp=0.\n",
    "    ), \n",
    "    Normalize.from_stats(*imagenet_stats)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f81d974-abb3-4c1d-865a-81544ff0122f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dsets.dataloaders(\n",
    "    after_item=[ToTensor], \n",
    "    after_batch=batch_tfms\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fe631e-a0af-4632-bd9c-f1720dc04777",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e44b40-c147-4c03-b7eb-4d145b66ec34",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c44dc1-cc30-4c38-a909-fa673cb532e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = vision_learner(dls, resnet34, metrics=[accuracy_multi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d5d79b-4a9f-4a92-8808-0ac91c413a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed6d6bc-6a3b-4bee-ae74-7301eb03d4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2c4080-3e7e-4b78-a1a6-80666cdd9cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tensor([[0.1, 0.5, 0.3, 0.7, 0.2]])\n",
    "torch.sigmoid(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d614f54-e25e-4782-856b-13ff0279143e",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.loss_func.thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34badbad-84c3-4e2b-a060-1b2885f24af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1193da19-8e6b-4831-b143-485986ad65dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1, slice(2e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3163a0d7-2ac5-4c92-811e-c5ca15bed20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(5, slice(2e-3/2.6**4, 2e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69dd9bc-f14a-487c-8d6a-8f67b38d5503",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results(figsize=(15,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c1c332e-89b8-415d-bd72-0995c39d6506",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = learn.model\n",
    "fname = get_x(df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5b45d36-a544-4201-a27b-8d54236cf21d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fname = '/home/zach/.fastai/data/planet_sample/train/train_21983.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e062c32-e93f-4611-a9c3-a7edada91546",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms import PILToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3f0e8e2-1f3e-42be-8b33-58c4c515d5a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "im = Image.open(fname)\n",
    "im = im.convert(\"RGB\")\n",
    "t_im = PILToTensor()(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecdb8c02-ebc2-443a-9a36-4e7aee88e746",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_im = t_im.unsqueeze(0)\n",
    "t_im = t_im.float().div_(255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e408c8-1cbf-418a-b9b2-7de4055c6f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = (\n",
    "    [0.485, 0.456, 0.406], \n",
    "    [0.229, 0.224, 0.225]\n",
    ")\n",
    "vector = [1]*4\n",
    "vector[1] = -1\n",
    "mean = tensor(mean).view(*vector)\n",
    "std = tensor(std).view(*vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9138bce-ad72-46b5-a239-5dc0cd9c45f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean.shape, std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ea047f-4e40-4a52-9c13-d491998fcabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_im = (t_im - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0beea08-3327-483e-b627-eade2c8a4b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384bfde5-2e5c-444c-918b-029017957cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    model.eval()\n",
    "    preds = model(t_im.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c761bf2-89c5-4ff4-bbd1-005f38e81dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3419db-955e-4f85-931f-d5d4febadb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_preds = torch.sigmoid(preds) > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58dc6bd-a4f9-475a-a530-5f813db75aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d449629b-fbe3-4b41-bb50-8365f17b02b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import compress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9179e8-62b2-4577-af81-390215e3ebc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "present_labels = list(compress(\n",
    "        data=list(different_labels), selectors=decoded_preds[0]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1949f60-2866-4e7e-aae7-23b29cd366fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "present_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030ce8aa-511e-4337-9fcf-e42c276f4f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.predict(fname)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9463d1a2-6ab0-42ed-89a7-708a3e35b71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(fname)\n",
    "im = im.convert(\"RGB\")\n",
    "t_im = PILToTensor()(im)\n",
    "\n",
    "mean, std = (\n",
    "    [0.485, 0.456, 0.406], \n",
    "    [0.229, 0.224, 0.225]\n",
    ")\n",
    "vector = [1]*4\n",
    "vector[1] = -1\n",
    "mean = tensor(mean).view(*vector)\n",
    "std = tensor(std).view(*vector)\n",
    "t_im = (t_im - mean) / std\n",
    "with torch.inference_mode():\n",
    "    model.eval()\n",
    "    preds = model(t_im.cuda())\n",
    "    \n",
    "decoded_preds = torch.sigmoid(preds) > 0.5\n",
    "\n",
    "present_labels = list(compress(\n",
    "        data=list(different_labels), selectors=decoded_preds[0]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0099cf64-e9b9-411e-b34f-75e9b804755b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
